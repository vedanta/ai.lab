{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is a simple script to load the OpenAI API key from a .env file\n",
    "# make sure to create a .env file with your OpenAI API key\n",
    "# also .env file is added to .gitignore so it won't be pushed to the git repository\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(\"OpenAI API Key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "response = llm.invoke(\"Tell me a joke about pancakes\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.5)\n",
    "\n",
    "try:\n",
    "    response = llm.invoke(\"Explain Donuts in simple terms.\")\n",
    "    print(response.content)\n",
    "except Exception as e:  # Catching general errors\n",
    "    print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Create an input box\n",
    "user_input = widgets.Text(placeholder=\"Type your message...\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to process user input\n",
    "def process_input(change):\n",
    "    if change[\"new\"].lower() in [\"exit\", \"quit\"]:\n",
    "        with output:\n",
    "            print(\"AI Assistant: Goodbye!\")\n",
    "    else:\n",
    "        response = llm.invoke(change[\"new\"])\n",
    "        with output:\n",
    "            print(f\"You: {change['new']}\")\n",
    "            print(f\"AI Assistant: {response.content}\\n\")\n",
    "\n",
    "# Attach function to user input\n",
    "user_input.observe(process_input, names=\"value\")\n",
    "\n",
    "# Display chat interface\n",
    "display(user_input, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
