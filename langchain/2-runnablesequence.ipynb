{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this is a simple script to load the OpenAI API key from a .env file\n",
    "# make sure to create a .env file with your OpenAI API key\n",
    "# also .env file is added to .gitignore so it won't be pushed to the git repository\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai # imports the openai library\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Get the OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(\"OpenAI API Key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  # Import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate  # Import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence  # Import RunnableSequence\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.5, max_tokens=100)  # Corrected temperature spelling\n",
    "\n",
    "# Define a Prompt Template\n",
    "template = PromptTemplate.from_template(\"Explain the concept of {concept} in a {tone} manner.\")\n",
    "\n",
    "# Correct Order: First Template, Then LLM\n",
    "pipeline = RunnableSequence(template, llm)  # Fixed argument order\n",
    "\n",
    "# Invoke the pipeline with the correct spelling of \"philosophical\"\n",
    "response = pipeline.invoke({\n",
    "    \"concept\": \"bagels\",\n",
    "    \"tone\": \"philosophical\"\n",
    "})\n",
    "\n",
    "# Print the response\n",
    "print(response.content)  # Access `.content` to get the text output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot prompt and RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0000ff\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"                                        \n",
    "    What is the hex code for the color red ? : #ff0000\n",
    "    What is the hex code of the color blue? : #00ff00\n",
    "    {question} : \n",
    "\"\"\"\n",
    "template = PromptTemplate.from_template(prompt)\n",
    "pipeline = RunnableSequence(template, llm)\n",
    "response = pipeline.invoke({\n",
    "    \"question\": \"what is the hex code for the color blue?\"\n",
    "})\n",
    "print(response.content)  # Access `.content` to get the text output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableSequence pre and post processing \n",
    "#### User Input → Pre-Processing → Prompt → LLM → Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gravity is a force that pulls objects towards each other. the more mass an object has, the stronger its gravitational pull. this is why things fall to the ground when you drop them. gravity is what keeps us on the ground and holds the planets in orbit around the sun.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Define a Prompt Template\n",
    "template = PromptTemplate.from_template(\"Explain {topic} in simple terms.\")\n",
    "\n",
    "# Pre-processing function (converts input to lowercase)\n",
    "def preprocess(inputs):\n",
    "    inputs[\"topic\"] = inputs[\"topic\"].lower()\n",
    "    return inputs\n",
    "\n",
    "# Post-processing function (converts response to uppercase)\n",
    "def postprocess(response):\n",
    "    return response.content.lower()\n",
    "\n",
    "# Create a RunnableSequence Pipeline with Pre/Post-Processing\n",
    "pipeline = RunnableSequence(preprocess, template, llm, postprocess)\n",
    "\n",
    "# Run the pipeline\n",
    "response = pipeline.invoke({\"topic\": \"gravity\"})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
